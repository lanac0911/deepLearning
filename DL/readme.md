# ğŸ”µ â… . æ·±åº¦å­¸ç¿’(Deep Learning)


### â—» æƒ³æ³•&æ–¹æ³•
> æˆ‘çš„é›»è…¦å¾ˆé›œï¼Œå¾ˆå¤šç¨‹å¼ä½”äº†ç©ºé–“ä¸å¥½æ¸…ç†ï¼Œå°è‡´è·‘èµ·ä¾†é€Ÿåº¦éå¸¸æ…¢ï¼Œä¹Ÿæœƒé‡åˆ°GPUä¸å¤ çš„æƒ…æ³ï¼Œéƒ½éœ€è¦æ…¢æ…¢å»èª¿æ•´

1. **è¼‰å…¥åœ–ç‰‡**
    * åŸæœ¬ç”¨file streamæ¦‚å¿µå»Loopè®€å–ï¼Œå¾Œä¾†ç™¼ç¾æ•ˆç‡å·®ï¼Œè¦èŠ±å¾ˆé•·æ™‚é–“è®€å–ï¼Œå¾Œæ”¹ç”¨`image_dataset_from_directory`
    * **image_dataset_from_directory**ï¼š[å®˜æ–¹ç¯„ä¾‹](https://www.tensorflow.org/tutorials/images/classification?hl=zh_tw)ä¸­ä½¿ç”¨çš„keraså…§å»ºå‡½å¼ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿çš„å°imgsé€²è¡Œè™•ç†
        * å¦‚ï¼šåœ–ç‰‡resizeã€batchå¤§å°ã€è³‡æ–™åˆ‡å‰²...)
        * [å®˜æ–¹æ–‡ä»¶](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory)

2. **è³‡æ–™é è™•ç†**
    * çºŒä¸Šï¼Œå°‡imgé™£åˆ—resize(çµ±ä¸€è¦æ ¼)
    * å†å°‡é™£åˆ—æ¯ä¸€å…ƒç´  / 255æˆä»‹æ–¼0-1çš„æ•¸ (æ¸›è¼•è¨ˆç®—è² æ“”)

3. **å»ºæ¨¡ã€è¨“ç·´**
    * ä½¿ç”¨CNNå»ºä¸‰å±¤
4. **å°å‡ºç›¸é—œè³‡è¨Š**
    * lossã€accuracy æŠ˜ç·šåœ–(æ”¶æ–‚) (åœ–ä¸€)
        * ä¸€é–‹å§‹æœ‰test dataçš„accuracyå¡ä½çš„æƒ…æ³ï¼Œè€ƒæ…®æ˜¯éåº¦é…é©çš„å•é¡Œï¼ŒåŠ ä¸Šdropout
    * æ··æ·†çŸ©é™£ (åœ–ä¸€)
        * é€”ä¸­ç™¼ç¾daisyå½çœŸ/å‡çš„æƒ…æ³ç‰¹åˆ¥å¤šï¼Œå¾Œä¾†ç™¼ç¾æ˜¯è‡ªå·±èª¤åˆªäº†éƒ¨åˆ†åœ–ç‰‡ 
    * éš¨æ©Ÿ10å¼µåœ–&å…¶çµæœ (åœ–äºŒ)

---

### â—» çµæœ

**æº–ç¢ºç‡ï¼š98.4%**

<img src="https://github.com/lanac0911/deepLearning/blob/main/imgs/m10.jpg" width="auto" height="400" />

`åœ–ä¸€`


<img src="https://github.com/lanac0911/deepLearning/blob/main/imgs/loss_acc.jpg" width="auto" height="400" />

`åœ–äºŒ`



### â—» code review
0. **åƒæ•¸è¨­å®š**
     ```python
    BATCH_SIZE = 32 #ä¸€æ¬¡æŠ“å–çš„é‡
    IMG_SIZE = 128 
    epochs = 15 #æ­¥æ•¸
    ```

1. **è®€å–åœ–ç‰‡(train/test data)**
    * å®šç¾©åœ–ç‰‡è³‡æ–™å¤¾è·¯å¾‘
     ```python
    data_dir = pathlib.Path('D:/lanac/deepLearning/DL/flowers')
    ```
2. **è®€imgs&éƒ¨åˆ†é è™•ç†**
    * seedï¼šæ¯æ¬¡éš¨æ”¶æˆä¸åŒçš„å€¼ï¼Œå»è½‰æ›data
    * image_size: å°æ‰€æœ‰åœ–ç‰‡çµ±ä¸€Size
    * batch_size: ä¸€æ¬¡æŠ“å–çš„é‡
    ```python
    
    train_data = tf.keras.preprocessing.image_dataset_from_directory(
      data_dir,
      seed=123,
      image_size=(IMG_SIZE, IMG_SIZE),
      batch_size=BATCH_SIZE
    )
    ```

3. **æ€§èƒ½å„ªåŒ–**
    * æ ¹æ“šå®˜æ–¹æ–‡ä»¶çš„å»ºè­°
    * .cache() : ç¬¬ä¸€æ¬¡loadå¾Œï¼Œæœƒå°‡imgä¿å­˜memory
    * .prefetch()ï¼šå¯ä»¥å…ˆåšé è™•ç†
    ```python
    AUTOTUNE = tf.data.AUTOTUNE
    train_data = train_data.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
    test_data = test_data.cache().prefetch(buffer_size=AUTOTUNE)
    ```    

4. **å»ºæ¨¡&éƒ¨åˆ†é è™•ç†**
    * åœ–ç‰‡/255 -> æ¸›è¼•è¨ˆç®—è² æ“”
    * ä¸‰å±¤(å·ç©+æ± åŒ–)
        * å¢åŠ ç¥ç¶“å…ƒæ•¸ç›®ï¼Œé€Ÿåº¦â†“ï¼Œæº–ç¢ºåº¦â†‘
        * DropOutï¼šæ²’æœ‰dropoutå‰ï¼Œæœƒæœ‰å°‘éƒ¨åˆ†ã€Œéåº¦é©é…ã€æƒ…æ³ï¼Œæ•…æ¯ä¸€å±¤å›ºå®šä¸Ÿæ‰ä¸€äº›ï¼Œå¢åŠ éš¨æ©Ÿæ€§
        * å›æ­¸åˆ°Denseé€²è¡Œåˆ†é¡
        *  Reluçš„å„ªé»åœ¨æ–¼ï¼šæ”¶æ–‚é€Ÿåº¦å¿«
       ```python
        Rescaling(1.0/255 ,input_shape=(IMG_SIZE, IMG_SIZE, 3)), #æ¨™æº–åŒ–(å› 0-255çµ„)
        #ç¬¬ä¸€å±¤
        Conv2D(16, (3,3), padding='same', activation='relu'),
        MaxPooling2D((2,2)),
        Dropout(0.2),
        #ç¬¬äºŒå±¤
        Conv2D(32, (3,3), padding='same', activation='relu'),
        MaxPooling2D((2,2)),
        Dropout(0.2),
        #ç¬¬ä¸‰å±¤
        Conv2D(64, (3,3), padding='same', activation='relu'),
        MaxPooling2D((2,2)),
        Dropout(0.2),
        #æ”¤å¹³ã€é€£æ¥
        Flatten(),
        Dense(128,   activation='relu'),
        Dense(5, activation='softmax'),       
       ```
5. **é–‹å§‹è¨“ç·´**
    * adamï¼šå­¸ç¿’é€Ÿåº¦æ˜¯å‹•æ…‹çš„ï¼Œè·Ÿè‘—æ¨¡å‹è€Œèª¿æ•´
    * sparse_categorical_crossentropyï¼šåˆ†é¡æ™‚å¸¸ç”¨é€™å€‹
   ```python
    model.compile(
        optimizer='adam', 
        loss='sparse_categorical_crossentropy', #åˆ†é¡æ™‚å¸¸ç”¨
        metrics=['accuracy']
    )

    history = model.fit(
      train_data,
      validation_data=test_data,
      epochs=epochs
    )  
   ```
   
6. **è®€å–è¨“ç·´è³‡æ–™**
    * è¨“ç·´å¾Œè²¼çš„æ¨™ç±¤&çœŸæ­£çš„æ¨™ç±¤
   ```python
    pred_labels = np.array([])
    test_labels = np.array([])
    for x, y in test_data:
        predictions = model.predict(x)
        pred_labels = np.concatenate([pred_labels, np.argmax(predictions,axis = 1) ])
        test_labels = np.concatenate([test_labels, y.numpy()])
   ```
   
   7. **ç•«åœ–**
       1. train data(è¨“ç·´é›†) & test data(æ¸¬è©¦é›†)çš„ (åœ–ä¸€)
           * lossæŠ˜ç·šåœ–(æ”¶æ–‚) 
           * accuracyæŠ˜ç·šåœ–(æ”¶æ–‚)
        2. æ··æ·†çŸ©é™£ (åœ–ä¸€)
        3. éš¨æ©Ÿå°å‡º10å¼µåœ–ç‰‡&å…¶çµæœ (åœ–äºŒ)


### â—» åƒè€ƒè³‡æ–™
 1. [TensorFlowå®˜æ–¹åˆ†é¡ç¯„ä¾‹](https://www.tensorflow.org/tutorials/images/classification?hl=zh_tw)
 2. [TensorFlowå®˜æ–¹image_dataset_from_directoryæ–‡ä»¶](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory)
